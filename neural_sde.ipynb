{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchsde  # For SDE solvers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'state', 'index_price', 'instrument_name', 'last_price',\n",
      "       'settlement_price', 'min_price', 'max_price', 'open_interest',\n",
      "       'mark_price', 'best_ask_price', 'best_bid_price', 'interest_rate',\n",
      "       'mark_iv', 'bid_iv', 'ask_iv', 'underlying_price', 'underlying_index',\n",
      "       'best_ask_amount', 'best_bid_amount', 'estimated_delivery_price',\n",
      "       'delivery_price', 'stats_high', 'stats_low', 'stats_price_change',\n",
      "       'stats_volume', 'stats_volume_usd', 'greeks_delta', 'greeks_gamma',\n",
      "       'greeks_rho', 'greeks_theta', 'greeks_vega', 'datetime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read in parquet file \n",
    "table = pq.read_table(\"/Users/167011/Documents/MQF/Thesis/Deribit_Data/deribit_options_2025-01-30_100k_rows.parquet\")\n",
    "# Convert to Panadas DataFrame\n",
    "df = table.to_pandas()\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = nan\n",
      "Epoch 100: Loss = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    120\u001b[0m loss \u001b[38;5;241m=\u001b[39m wasserstein_loss(sde_model, real_samples, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure_mcmc/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure_mcmc/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure_mcmc/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define log-price to ensure positive values\n",
    "df['log_price'] = np.log(df['underlying_price'])\n",
    "# Define log-return\n",
    "df['log_return'] = df['log_price'].diff().fillna(0)\n",
    "\n",
    "# Feature selection\n",
    "drift_features = ['index_price', 'underlying_price', 'stats_price_change',\n",
    "                  'open_interest', 'stats_volume', 'stats_volume_usd', \n",
    "                  'interest_rate', 'best_ask_price', 'best_bid_price', \n",
    "                  'best_ask_amount', 'best_bid_amount']\n",
    "\n",
    "diffusion_features = ['mark_iv', 'bid_iv', 'ask_iv', 'greeks_vega', 'greeks_gamma',\n",
    "                      'best_ask_price', 'best_bid_price']\n",
    "\n",
    "# Define drift and diffusion coefficients (Parametrised by neural networks)\n",
    "class NeuralDrift(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=100):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)  # Output is 1D drift\n",
    "        )\n",
    "    \n",
    "    def forward(self, t, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class NeuralDiffusion(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=100):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softplus()  # Ensure non-negative volatility\n",
    "        )\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Instantiate networks\n",
    "drift_net = NeuralDrift(len(drift_features))\n",
    "diffusion_net = NeuralDiffusion(len(diffusion_features))\n",
    "\n",
    "# Combine all features\n",
    "features = list(set(drift_features + diffusion_features))\n",
    "\n",
    "# Index mappings for Drift and Diffusion features\n",
    "drift_idx = [features.index(f) for f in drift_features]\n",
    "diff_idx = [features.index(f) for f in diffusion_features]\n",
    "\n",
    "# Define Neural SDE\n",
    "class NeuralSDE(torchsde.SDEIto):\n",
    "    def __init__(self, drift_net, diffusion_net, drift_idx, diff_idx):\n",
    "        super().__init__(noise_type=\"diagonal\")\n",
    "        self.drift_net = drift_net\n",
    "        self.diffusion_net = diffusion_net\n",
    "        self.drift_idx = drift_idx\n",
    "        self.diff_idx = diff_idx\n",
    "    \n",
    "    def f(self, t, x):  # Drift function\n",
    "        # Selecting drift features\n",
    "        x_drift = x[:, self.drift_idx]\n",
    "        drift_component = self.drift_net(t, x_drift)\n",
    "        # Init full drift vector (with zeros)\n",
    "        full_drift = torch.zeros_like(x)\n",
    "        # Insert drift component into full drift vector\n",
    "        full_drift[:, self.drift_idx] = drift_component\n",
    "        return full_drift\n",
    "    \n",
    "    def g(self, t, x):  # Diffusion function\n",
    "        # Selecting diffusion features\n",
    "        x_diff = x[:, self.diff_idx]\n",
    "        diffusion_component = self.diffusion_net(t, x_diff)\n",
    "        # Init full diffusion vector (with zeros)\n",
    "        full_diffusion = torch.zeros_like(x)\n",
    "        # Insert diffusion component into full diffusion vector\n",
    "        full_diffusion[:, self.diff_idx] = diffusion_component\n",
    "        return full_diffusion\n",
    "\n",
    "# Instantiate SDE model with the index lists\n",
    "sde_model = NeuralSDE(drift_net, diffusion_net, drift_idx, diff_idx)\n",
    "\n",
    "# Defining Wasserstein Loss\n",
    "def wasserstein_loss(model, real_samples, batch_size=64):\n",
    "    \"\"\"Computes Wasserstein-1 distance loss\"\"\"\n",
    "    # Generate synthetic samples\n",
    "    num_steps = 100\n",
    "    # t = torch.linspace(0, 1, steps=len(real_samples)).reshape(-1, 1) \n",
    "    t = torch.linspace(0, 1, steps=num_steps).reshape(-1, 1)\n",
    "    # Generate batch of initial conditions\n",
    "    x0 = real_samples[0].view(1, -1).repeat(batch_size, 1)\n",
    "    # Generate synthetic trajectories\n",
    "    generated_samples = torchsde.sdeint(model, x0, t)\n",
    "    # Take the final time step for each trajectory\n",
    "    generated_final = generated_samples[-1]\n",
    "    # Sample a batch of real samples (shape: batch_size x state_dim)\n",
    "    idx = torch.randperm(real_samples.shape[0])[:batch_size]\n",
    "    real_batch = real_samples[idx]\n",
    "    \n",
    "    # Sort each column of the generated and real samples and compute the mean absolute difference\n",
    "    real_sorted, _ = real_batch.sort(dim=0)\n",
    "    gen_sorted, _ = generated_final.sort(dim=0)\n",
    "    loss = torch.mean(torch.abs(real_sorted - gen_sorted))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Training the model\n",
    "optimizer = optim.Adam(list(drift_net.parameters()) + list(diffusion_net.parameters()), lr=1e-3)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    real_samples = torch.tensor(df[features].values, dtype=torch.float32)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = wasserstein_loss(sde_model, real_samples, batch_size=64)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item()}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       nan, 0.0000e+00, 1.0380e+05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.2993e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.6000e-03, 1.0382e+05, 0.0000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(df[features].values, dtype=torch.float32)[0].view(1, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "structure_mcmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
